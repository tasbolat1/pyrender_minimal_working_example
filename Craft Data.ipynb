{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8683ae8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import trimesh\n",
    "import rospy\n",
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from IPython import display\n",
    "from PIL import Image\n",
    "import io\n",
    "from pathlib import Path\n",
    "import msgpack\n",
    "import json\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "import math\n",
    "import session_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb35bd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## essential to open pupilabs pldata files\n",
    "\n",
    "import collections\n",
    "import collections.abc\n",
    "import copy\n",
    "import logging\n",
    "import os\n",
    "import pickle\n",
    "import traceback as tb\n",
    "import types\n",
    "from glob import iglob\n",
    "from pathlib import Path\n",
    "\n",
    "import msgpack\n",
    "import numpy as np\n",
    "from rich.progress import track\n",
    "\n",
    "assert (\n",
    "    msgpack.version[0] == 1\n",
    "), \"msgpack out of date, please upgrade to version (1, 0, 0)\"\n",
    "\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "UnpicklingError = pickle.UnpicklingError\n",
    "\n",
    "PLData = collections.namedtuple(\"PLData\", [\"data\", \"timestamps\", \"topics\"])\n",
    "\n",
    "class _Empty:\n",
    "    def purge_cache(self):\n",
    "        pass\n",
    "\n",
    "def load_pldata_file(directory, topic, track_progress_in_console: bool = True):\n",
    "    ts_file = os.path.join(directory, topic + \"_timestamps.npy\")\n",
    "    msgpack_file = os.path.join(directory, topic + \".pldata\")\n",
    "    try:\n",
    "        data = collections.deque()\n",
    "        topics = collections.deque()\n",
    "        extract_ts = False\n",
    "        try:\n",
    "            data_ts = np.load(ts_file)\n",
    "        except FileNotFoundError:\n",
    "            data_ts = []\n",
    "            extract_ts = True\n",
    "            logger.warning(\n",
    "                f\"Timestamp file not found at expected location `{ts_file}`.\"\n",
    "                \" Attempting to fallback to msgpack-serialized timestamps.\"\n",
    "            )\n",
    "        with open(msgpack_file, \"rb\") as fh:\n",
    "            unpacker = msgpack.Unpacker(fh, use_list=False, strict_map_key=False)\n",
    "            if track_progress_in_console:\n",
    "                unpacker = track(\n",
    "                    unpacker, description=f\"Loading {topic} data\", total=len(data_ts)\n",
    "                )\n",
    "            for topic, payload in unpacker:\n",
    "                datum = Serialized_Dict(msgpack_bytes=payload)\n",
    "                data.append(datum)\n",
    "                topics.append(topic)\n",
    "                if extract_ts:\n",
    "                    data_ts.append(datum[\"timestamp\"])\n",
    "    except FileNotFoundError as err:\n",
    "        logger.debug(err)\n",
    "        data = []\n",
    "        data_ts = []\n",
    "        topics = []\n",
    "\n",
    "    return PLData(data, data_ts, topics)\n",
    "\n",
    "\n",
    "class Serialized_Dict:\n",
    "    __slots__ = [\"_ser_data\", \"_data\"]\n",
    "    cache_len = 100\n",
    "    _cache_ref = [_Empty()] * cache_len\n",
    "    MSGPACK_EXT_CODE = 13\n",
    "\n",
    "    def __init__(self, python_dict=None, msgpack_bytes=None):\n",
    "        if type(python_dict) is dict:\n",
    "            self._ser_data = msgpack.packb(\n",
    "                python_dict, use_bin_type=True, default=self.packing_hook\n",
    "            )\n",
    "        elif type(msgpack_bytes) is bytes:\n",
    "            self._ser_data = msgpack_bytes\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"You did not supply mapping or payload to Serialized_Dict.\"\n",
    "            )\n",
    "        self._data = None\n",
    "\n",
    "    def _deser(self):\n",
    "        if not self._data:\n",
    "            self._data = msgpack.unpackb(\n",
    "                self._ser_data,\n",
    "                use_list=False,\n",
    "                object_hook=self.unpacking_object_hook,\n",
    "                ext_hook=self.unpacking_ext_hook,\n",
    "                strict_map_key=False,\n",
    "            )\n",
    "            self._cache_ref.pop(0).purge_cache()\n",
    "            self._cache_ref.append(self)\n",
    "\n",
    "    def __getstate__(self):\n",
    "        return self._ser_data\n",
    "\n",
    "    def __setstate__(self, msgpack_bytes):\n",
    "        self._ser_data = msgpack_bytes\n",
    "        self._data = None\n",
    "\n",
    "    @classmethod\n",
    "    def unpacking_object_hook(self, obj):\n",
    "        if type(obj) is dict:\n",
    "            return types.MappingProxyType(obj)\n",
    "\n",
    "    @classmethod\n",
    "    def packing_hook(self, obj):\n",
    "        if isinstance(obj, self):\n",
    "            return msgpack.ExtType(self.MSGPACK_EXT_CODE, obj.serialized)\n",
    "        raise TypeError(f\"can't serialize {type(obj)}({repr(obj)})\")\n",
    "\n",
    "    @classmethod\n",
    "    def unpacking_ext_hook(self, code, data):\n",
    "        if code == self.MSGPACK_EXT_CODE:\n",
    "            return self(msgpack_bytes=data)\n",
    "        return msgpack.ExtType(code, data)\n",
    "\n",
    "    def purge_cache(self):\n",
    "        self._data = None\n",
    "\n",
    "    @property\n",
    "    def serialized(self):\n",
    "        return self._ser_data\n",
    "\n",
    "    def __setitem__(self, key, item):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        self._deser()\n",
    "        return self._data[key]\n",
    "\n",
    "    def __repr__(self):\n",
    "        self._deser()\n",
    "        return f\"Serialized_Dict({repr(self._data)})\"\n",
    "\n",
    "    @property\n",
    "    def len(self):\n",
    "        \"\"\"Replacement implementation for __len__\n",
    "\n",
    "        If __len__ is defined numpy will recognize this as nested structure and\n",
    "        start deserializing everything instead of using this object as it is.\n",
    "        \"\"\"\n",
    "        self._deser()\n",
    "        return len(self._data)\n",
    "\n",
    "    def __delitem__(self, key):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def get(self, key, default):\n",
    "        try:\n",
    "            return self[key]\n",
    "        except KeyError:\n",
    "            return default\n",
    "\n",
    "    def clear(self):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def copy(self):\n",
    "        self._deser()\n",
    "        return self._data.copy()\n",
    "\n",
    "    def __deepcopy__(self, memo=None):\n",
    "        return _recursive_deep_copy(self)\n",
    "\n",
    "    def has_key(self, k):\n",
    "        self._deser()\n",
    "        return k in self._data\n",
    "\n",
    "    def update(self, *args, **kwargs):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def keys(self):\n",
    "        self._deser()\n",
    "        return self._data.keys()\n",
    "\n",
    "    def values(self):\n",
    "        self._deser()\n",
    "        return self._data.values()\n",
    "\n",
    "    def items(self):\n",
    "        self._deser()\n",
    "        return self._data.items()\n",
    "\n",
    "    def pop(self, *args):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def __cmp__(self, dict_):\n",
    "        self._deser()\n",
    "        return self._data.__cmp__(dict_)\n",
    "\n",
    "    def __contains__(self, item):\n",
    "        self._deser()\n",
    "        return item in self._data\n",
    "\n",
    "    def __iter__(self):\n",
    "        self._deser()\n",
    "        return iter(self._data)\n",
    "\n",
    "    def _deep_copy_serialized_dict(self):\n",
    "        dict_copy = self._deep_copy_dict()\n",
    "        return Serialized_Dict(python_dict=dict_copy)\n",
    "\n",
    "    def _deep_copy_dict(self):\n",
    "        def unpacking_ext_hook(self, code, data):\n",
    "            if code == self.MSGPACK_EXT_CODE:\n",
    "                return type(self)(msgpack_bytes=data)._deep_copy_dict()\n",
    "            return msgpack.ExtType(code, data)\n",
    "\n",
    "        return msgpack.unpackb(\n",
    "            self._ser_data,\n",
    "            use_list=False,\n",
    "            ext_hook=unpacking_ext_hook,\n",
    "        )\n",
    "    \n",
    "def load_pupil(trial):\n",
    "    # please ensure your trial numbers for the pupilabs are actually correct\n",
    "    # input: trial name\n",
    "    # output: [timestamp, gaze_point_3d, eye_center_3d, confidence_score]\n",
    "    \n",
    "    starting_directory = f'D:/Actual Cornell Data/pupilabs/{trial}/000'\n",
    "    with open(fr'{starting_directory}/info.player.json') as json_file:\n",
    "        data = json.load(json_file)\n",
    "        starting_sys_time = data['start_time_system_s']\n",
    "        starting_pupil_time = data['start_time_synced_s']\n",
    "        time_delay = starting_sys_time - starting_pupil_time\n",
    "    \n",
    "    gazes = np.load(f\"{starting_directory}/gaze_timestamps.npy\")\n",
    "    gazes_corrected = gazes - starting_pupil_time + starting_sys_time\n",
    "    \n",
    "    total_data = []\n",
    "    gaze_data = load_pldata_file(starting_directory, \"gaze\")\n",
    "\n",
    "    for gaze_datum in gaze_data.data:\n",
    "        total_data.append((gaze_datum['timestamp'] + time_delay, \n",
    "                           gaze_datum['gaze_normal_3d'], \n",
    "                           gaze_datum['confidence']))\n",
    "    \n",
    "    return total_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0fa5e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mocap_pickle(fname):\n",
    "    '''\n",
    "    Reads Mocap pickles specifically and returns the following:\n",
    "    [ids] - Rigid body names\n",
    "    {dict} - dictionary of {timestamps: [(id, pos)] world position of each joint}\n",
    "    '''\n",
    "    starting_directory = f'D:/Actual Cornell Data/mocap/{fname}_mocap.pkl'\n",
    "    with open(starting_directory, 'rb') as f:\n",
    "        ids = []\n",
    "        joint_pos = {}\n",
    "        while 1:\n",
    "            try:\n",
    "                data = pickle.load(f)\n",
    "                if data.ns not in ids:\n",
    "                    ids.append(data.ns)\n",
    "                timestamp = data.header.stamp.secs + 1e-3 * (data.header.stamp.nsecs // 1e6)\n",
    "                if timestamp not in joint_pos:\n",
    "                    joint_pos[timestamp] = {}\n",
    "                joint_pos[timestamp][data.ns] = [data.pose.position.x, data.pose.position.y, data.pose.position.z,\n",
    "                                                 data.pose.orientation.x, data.pose.orientation.y, data.pose.orientation.z, data.pose.orientation.w]\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                break\n",
    "    \n",
    "    joint_list = []\n",
    "    for timestamp in joint_pos.keys():\n",
    "        joint_list.append((timestamp, joint_pos[timestamp]))\n",
    "    return ids, sorted(joint_list, key = lambda x: x[0], reverse=False)\n",
    "\n",
    "def load_mocap_txt(fname):\n",
    "    starting_directory = f'D:/Actual Cornell Data/mocap/{fname}_mocap.txt'\n",
    "    with open(starting_directory, 'r') as f:\n",
    "        ids = []\n",
    "        joint_pos = {}\n",
    "        f.readline()\n",
    "        for line in f:\n",
    "            ns, time_second, time_nanosecond, pos_x, pos_y, pos_z, or_x, or_y, or_z, or_w, delay = line.split(', ')\n",
    "            timestamp = int(time_second) + 1e-3 * (int(time_nanosecond) // 1e6)\n",
    "            if ns not in ids:\n",
    "                ids.append(ns)\n",
    "            if timestamp not in joint_pos:\n",
    "                joint_pos[timestamp] = {}\n",
    "            joint_pos[timestamp][ns] = [pos_x, pos_y, pos_z, or_x, or_y, or_z, or_w]\n",
    "    joint_list = []\n",
    "    for timestamp in joint_pos.keys():\n",
    "        joint_list.append((timestamp, joint_pos[timestamp]))\n",
    "    return ids, sorted(joint_list, key = lambda x: x[0], reverse=False)\n",
    "\n",
    "\n",
    "def load_mocap(trial):\n",
    "    OT, manikin, task = trial.split('-')[:3]\n",
    "    if int(OT) > 9:\n",
    "        return load_mocap_txt(trial)\n",
    "    else:\n",
    "        return load_mocap_pickle(trial)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f78db7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_skin(trial):\n",
    "    starting_directory = f'D:/Actual Cornell Data/Skin/{trial}_skin.pkl'\n",
    "    with open(starting_directory, 'rb') as f:\n",
    "        skin_data = []\n",
    "        while 1:\n",
    "            try:\n",
    "                data = pickle.load(f)\n",
    "                timestamp = data[0].secs + (data[0].nsecs * 1e-9)\n",
    "                skin_data.append((timestamp, data[1]))\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                break\n",
    "    return sorted(skin_data, key = lambda x: x[0], reverse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46b62cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "'''\n",
    "Skeleton reconstructor\n",
    "\n",
    "This code takes a pkl file containing mocap data and attempts to reconstruct a skeleton.\n",
    "Results are rendered in 3D\n",
    "'''\n",
    "####################\n",
    "\n",
    "# edge list to reconstruct skeleton\n",
    "\n",
    "# for additionals it is a link between <min> and <max> of those joints\n",
    "\n",
    "skeleton_links_female = [\n",
    "    \"F_RUpperArm\", \"F_LUpperArm\", \"F_LThigh\", \"F_RThigh\"\n",
    "]\n",
    "\n",
    "\n",
    "skeleton_links_male = [\n",
    "    \"M_RUpperArm\", \"M_LUpperArm\", \"M_Hips\", \"M_LThigh\", \"M_RThigh\"\n",
    "]\n",
    "\n",
    "IDS = ['Hoyer_Base_L', 'M_Head', 'Hoyer_Base_R', 'M_Torso', 'C_Head', \n",
    " 'Hoyer_Top', 'M_RCalf', 'F_RCalf', 'M_RThigh', 'Bed_Foot', 'PPS_L', 'F_LThigh', \n",
    " 'Bedpan', 'Wheelchair', 'Commode', 'M_Hips', 'M_LUpperArm', 'M_RUpperArm', 'M_RLowerArm', \n",
    " 'F_RLowerArm', 'F_Torso', 'F_LCalf', 'F_RThigh', 'F_LUpperArm', 'F_Head', 'Bed_Head', 'M_LThigh', \n",
    " 'PPS_R', 'F_Hips', 'M_LCalf', 'Brush', 'M_LLowerArm', 'F_RUpperArm', 'F_LLowerArm']\n",
    "\n",
    "marker_positions = {}\n",
    "\n",
    "def load_markers(filename):\n",
    "    starting_directory = f'D:/Actual Cornell Data/mocap/Joint Positions/{filename}.txt'\n",
    "    global marker_positions\n",
    "    marker_positions = {}\n",
    "    \n",
    "    with open(starting_directory, 'r') as f:\n",
    "        line = f.readline()\n",
    "        found_start = False\n",
    "        rigid_set = \"\"\n",
    "        while line != '':\n",
    "            if not found_start:\n",
    "                if \"RigidBody Name\" not in line:\n",
    "                    line = f.readline()\n",
    "                    continue\n",
    "                else:\n",
    "                    rigid_set = line.split('RigidBody Name : ')[1].replace('\\n', '')\n",
    "                    found_start = True\n",
    "                    marker_positions[rigid_set] = []\n",
    "            else:\n",
    "                if \"Data Description\" in line:\n",
    "                    found_start = False\n",
    "                else:\n",
    "                    if \"Position\" in line:\n",
    "                        position = line.split(\"Position: \")[1].replace('\\n', '')\n",
    "                        x, y, z = position.split(\", \")\n",
    "                        marker_positions[rigid_set].append(list(map(float, [x, y, z])))\n",
    "            line = f.readline()\n",
    "            \n",
    "\n",
    "def visualize_keypoints(joint_type, show = False):\n",
    "    markers = np.array(marker_positions[joint_type])\n",
    "    ### because the markers are all initialized when the manikin is on the bed in a fixed position, we can simply \n",
    "    ### use the min/max in the Z-direction to obtain the front/end of the body markers\n",
    "    ### meanwhile for the torso, the two top most -Z will form the left/right shoulder, and the midpoint can be \n",
    "    ### extrapolated into the midsection\n",
    "    \n",
    "    if \"Torso\" in joint_type:\n",
    "        forward_most = np.argmin(markers[:, 0])\n",
    "        back_most = np.argmax(markers[:, 0])\n",
    "    else:\n",
    "        forward_most = np.argmax(markers[:, 2])\n",
    "        back_most = np.argmin(markers[:, 2])\n",
    "    colours = {\n",
    "        forward_most: [255, 0, 0, 255],\n",
    "        back_most: [0, 255, 0, 255]\n",
    "    }\n",
    "    \n",
    "    if show:\n",
    "        scene = trimesh.Scene()\n",
    "        for i in range(len(markers)):\n",
    "            colour = colours[i] if i in colours else [0, 0, 0, 255]\n",
    "            marker = markers[i]\n",
    "            cloud = trimesh.points.PointCloud(np.array([marker]), colors=np.tile(np.array(colour), (1, 1)))\n",
    "            scene.add_geometry(cloud)\n",
    "        return scene\n",
    "    else:\n",
    "        return markers[forward_most], markers[back_most]\n",
    "\n",
    "def make_transformation_matrix(pose):\n",
    "    # assumes lst is in the form of [x, y, z, ox, oy, oz, ow]\n",
    "    pos_x, pos_y, pos_z, or_x, or_y, or_z, or_w = pose\n",
    "    transformation_matrix = np.eye(4)\n",
    "    transformation_matrix[:3, :3] = R.from_quat([or_x, or_y, or_z, or_w]).as_matrix()\n",
    "    transformation_matrix[:3, 3] = [pos_x, pos_y, pos_z]\n",
    "    return transformation_matrix\n",
    "    \n",
    "def get_point(pose, joint_name):\n",
    "    # returns the <front point> and <back point>\n",
    "    pos_x, pos_y, pos_z, or_x, or_y, or_z, or_w = pose\n",
    "    transformation_world_to_obj = make_transformation_matrix(pose)\n",
    "\n",
    "    transformation_centroid_to_offshoot_front = np.eye(4)\n",
    "    transformation_centroid_to_offshoot_back = np.eye(4)\n",
    "\n",
    "    offshoot_forward, offshoot_back = visualize_keypoints(joint_name)\n",
    "    transformation_centroid_to_offshoot_front[:3, 3] = offshoot_forward\n",
    "    transformation_centroid_to_offshoot_back[:3, 3] = offshoot_back\n",
    "\n",
    "    transform_world_to_front = transformation_world_to_obj @ transformation_centroid_to_offshoot_front\n",
    "    transform_world_to_back = transformation_world_to_obj @ transformation_centroid_to_offshoot_back\n",
    "\n",
    "    front_point = (transform_world_to_front @ np.array([0, 0, 0, 1]))[:3].T\n",
    "    back_point = (transform_world_to_back @ np.array([0, 0, 0, 1]))[:3].T\n",
    "    \n",
    "    return front_point, back_point\n",
    "\n",
    "def skeleton_reconstruct(skeleton_positions, gender):\n",
    "    # input: dictionary {ID: [general_position]}\n",
    "    joints = skeleton_links_female if gender == 0 else skeleton_links_male\n",
    "    lines = []\n",
    "    centroids = []\n",
    "    print(joints)\n",
    "    for joint_2 in joints:\n",
    "        try:\n",
    "            \n",
    "            pos_x, pos_y, pos_z, or_x, or_y, or_z, or_w = skeleton_positions[joint_2]\n",
    "            centroids.append([pos_x, pos_y, pos_z])\n",
    "            front_point, back_point = get_point(skeleton_positions[joint_2], joint_2)\n",
    "            \n",
    "#             if list(np.array(front_point).nonzero()[0]) == [] or list(np.array(back_point).nonzero()[0]) == []:\n",
    "#                 continue\n",
    "\n",
    "            lines.append([front_point, back_point, joint_2, joint_2])\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            continue\n",
    "    formatter = \"F\" if gender == 0 else \"M\"\n",
    "    if f\"{formatter}_LUpperArm\" in skeleton_positions and f\"{formatter}_RUpperArm\" in skeleton_positions:\n",
    "        max_L, min_L = get_point(skeleton_positions[f\"{formatter}_LUpperArm\"], f\"{formatter}_LUpperArm\")\n",
    "        max_R, min_R = get_point(skeleton_positions[f\"{formatter}_RUpperArm\"], f\"{formatter}_RUpperArm\")\n",
    "        \n",
    "        lines.append([min_L, min_R, f\"{formatter}_LShoulder\", f\"{formatter}_RShoulder\"])\n",
    "        print(\"Added shoulder-shoulder links\")\n",
    "        \n",
    "        # for the lower arm we will snap it to the end point of the upper arms directly\n",
    "        if f\"{formatter}_LLowerArm\" in skeleton_positions and f\"{formatter}_RLowerArm\" in skeleton_positions:\n",
    "            max_LL, min_LL = get_point(skeleton_positions[f\"{formatter}_LLowerArm\"], f\"{formatter}_LLowerArm\")\n",
    "            max_RL, min_RL = get_point(skeleton_positions[f\"{formatter}_RLowerArm\"], f\"{formatter}_RLowerArm\")\n",
    "            \n",
    "            lines.append([max_L, max_LL, f\"{formatter}_LElbow\", f\"{formatter}_LWrist\"])\n",
    "            lines.append([max_R, max_RL, f\"{formatter}_RElbow\", f\"{formatter}_RWrist\"])\n",
    "        \n",
    "        if f\"{formatter}_Hips\" in skeleton_positions:\n",
    "            mid_arms = (min_L + min_R) / 2\n",
    "            x, y, z, _, _, _, _ = skeleton_positions[f\"{formatter}_Hips\"]\n",
    "            # for greater accuracy we will use the point at the crotch so we change the Z value to the max\n",
    "            max_hips, _ = get_point(skeleton_positions[f\"{formatter}_Hips\"], f\"{formatter}_Hips\")\n",
    "            z = max_hips[2]\n",
    "            \n",
    "            lines.append([mid_arms, [x, y, z], f\"{formatter}_Torso\", f\"{formatter}_Hips\"])\n",
    "            print(\"Added torso-hip links\")\n",
    "            \n",
    "            if f\"{formatter}_LThigh\" in skeleton_positions and f\"{formatter}_RThigh\" in skeleton_positions:\n",
    "                _, min_L = get_point(skeleton_positions[f\"{formatter}_LThigh\"], f\"{formatter}_LThigh\")\n",
    "                _, min_R = get_point(skeleton_positions[f\"{formatter}_RThigh\"], f\"{formatter}_RThigh\")\n",
    "                \n",
    "                \n",
    "                lines.append([min_L, [x, y, z], f\"{formatter}_LThigh\", f\"{formatter}_Hips\"])\n",
    "                lines.append([min_R, [x, y, z], f\"{formatter}_RThigh\", f\"{formatter}_Hips\"])\n",
    "                print(\"Added hip-thigh links\")\n",
    "            \n",
    "    if f\"{formatter}_LThigh\" in skeleton_positions and f\"{formatter}_RThigh\" in skeleton_positions:\n",
    "        max_L, min_L = get_point(skeleton_positions[f\"{formatter}_LThigh\"], f\"{formatter}_LThigh\")\n",
    "        max_R, min_R = get_point(skeleton_positions[f\"{formatter}_RThigh\"], f\"{formatter}_RThigh\")\n",
    "        \n",
    "        # snap the calf line from the knee to the ankle\n",
    "        if f\"{formatter}_LCalf\" in skeleton_positions and f\"{formatter}_RCalf\" in skeleton_positions:\n",
    "            max_LL, min_LL = get_point(skeleton_positions[f\"{formatter}_LCalf\"], f\"{formatter}_LCalf\")\n",
    "            max_RL, min_RL = get_point(skeleton_positions[f\"{formatter}_RCalf\"], f\"{formatter}_RCalf\")\n",
    "            \n",
    "            lines.append([max_L, max_LL, f\"{formatter}_LKnee\", f\"{formatter}_LAnkle\"])\n",
    "            lines.append([max_R, max_RL, f\"{formatter}_RKnee\", f\"{formatter}_RAnkle\"])\n",
    "    return lines, centroids\n",
    "\n",
    "# NAME = f\"Cornell Data/7-0-1_mocap.pkl\"\n",
    "# skeleton_lines = skeleton_reconstruct(NAME)\n",
    "\n",
    "#scene.show()\n",
    "\n",
    "load_markers('18')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d214f958",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_points = [\n",
    "    \"C_Head\",\n",
    "    \"\"\n",
    "]\n",
    "\n",
    "def total_construct(trial):\n",
    "    # input: trial - this will be the trial number e.g. '0-0-12'\n",
    "    # output: [<frame_data>, ]: \n",
    "    # a list of frame data with the following details:\n",
    "    # (timestamp, [joint_positions], [skin_taxels], [optical_center, gaze_point])\n",
    "    # this will give the closest approximate data per 1/15th of a second\n",
    "    \n",
    "    skin_data = load_skin(trial)\n",
    "    pupil_data = load_pupil(trial)\n",
    "    mocap_data = load_mocap(trial)\n",
    "    \n",
    "    data = []\n",
    "    \n",
    "    '''\n",
    "    Assemble the data\n",
    "    - in intervals of 1/15 a second:\n",
    "        - skin: find the data that is closest to the timestamp\n",
    "        - pupilabs: find the data within 1/30s of each timestamp. \n",
    "                    discard all confidence values below 0.5, and take centroid of the rest\n",
    "        - mocap: find the closest data to the timestamp that has all the skeleton information + hands + head position present\n",
    "    '''\n",
    "    \n",
    "    start = int(min((skin_data[0][0], pupil_data[0][0], mocap_data[1][0][0])))\n",
    "    end = int(max((skin_data[-1][0], pupil_data[-1][0], mocap_data[1][-1][0])))\n",
    "    print(f\"Identified the start time as {datetime.fromtimestamp(start)} for trial {trial}\")\n",
    "    print(f\"Identified the end time as {datetime.fromtimestamp(end)} for trial {trial}\")\n",
    "    \n",
    "    timestamps_skins = np.array(list(map(lambda x: x[0], skin_data)))\n",
    "    timestamps_pupil = np.array(list(map(lambda x: x[0], pupil_data)))\n",
    "    timestamps_mocap = np.array(list(map(lambda x: x[0], mocap_data[1])))\n",
    "    print(timestamps_pupil)\n",
    "    total_data = []\n",
    "    current_time = start\n",
    "    while current_time < end:\n",
    "        closest_skin_pos = np.argmin(np.abs(timestamps_skins - current_time))\n",
    "        \n",
    "        ## use the closest skin value\n",
    "        current_skins = skin_data[closest_skin_pos][1]\n",
    "        \n",
    "        pupilabs_ranges = (np.abs(timestamps_pupil - current_time) < 1/30).nonzero()[0]\n",
    "        pupilabs_ranges = sorted(pupilabs_ranges, key = lambda x: abs(timestamps_pupil[x] - current_time))\n",
    "            \n",
    "        pupil_in_range = []\n",
    "        gazes = []\n",
    "        norm_vector = [0, 0, 0]\n",
    "        confidence = 0\n",
    "        for index in pupilabs_ranges:\n",
    "            _, norm_vector, confidence = pupil_data[index]\n",
    "            if confidence < 0.5:\n",
    "                continue\n",
    "            break\n",
    "            # gazes.append(norm_vector)\n",
    "        \n",
    "        ## use the gaze/eye centroids\n",
    "        gaze_centroid = np.mean(np.array(gazes), axis=0)\n",
    "        \n",
    "        mocap_ranges = (np.abs(timestamps_mocap - current_time) < 1/30).nonzero()[0]\n",
    "        mocap_ranges = sorted(mocap_ranges, key = lambda x: abs(timestamps_mocap[x] - current_time))\n",
    "        \n",
    "        detected_keypoints = {}\n",
    "        for index in mocap_ranges:\n",
    "            _, detected_keypoints = mocap_data[1][index]\n",
    "            if len(detected_keypoints.keys()) < 10 or \"C_Head\" not in detected_keypoints:\n",
    "                continue\n",
    "            break\n",
    "        \n",
    "        \n",
    "        total_data.append((current_time, current_skins, (norm_vector, confidence), detected_keypoints))\n",
    "        current_time += 1/15\n",
    "    \n",
    "    return total_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3f0ef94c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2127b096a63645d5b7e9417ce7a8e59a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ran out of input\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified the start time as 2023-10-01 20:37:28 for trial 18-0-7\n",
      "Identified the end time as 2023-10-01 20:40:40 for trial 18-0-7\n",
      "[1.69616385e+09 1.69616385e+09 1.69616385e+09 ... 1.69616404e+09\n",
      " 1.69616404e+09 1.69616404e+09]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1696163852.5999956,\n",
       " [47.53428757545806,\n",
       "  52.87248224653414,\n",
       "  51.2847875470591,\n",
       "  52.50634422138048,\n",
       "  68.62507896007567,\n",
       "  -29.58911539164799,\n",
       "  -11.24207402880338,\n",
       "  71.95991995747758,\n",
       "  104.9769529815683,\n",
       "  76.7388382078146,\n",
       "  104.50751560831425,\n",
       "  142.40802868168336,\n",
       "  -19.69256367385808,\n",
       "  70.804011161487,\n",
       "  69.42830900813227,\n",
       "  123.63906551378895,\n",
       "  91.43783134779086,\n",
       "  50.477190216378744,\n",
       "  73.47734076696136,\n",
       "  218.02429907528344,\n",
       "  183.38120502562035,\n",
       "  50.025240344121364,\n",
       "  51.013491852760126,\n",
       "  47.67336493544612,\n",
       "  52.883348388887164,\n",
       "  59.15761027412616,\n",
       "  47.89774420078616,\n",
       "  56.7053123733189,\n",
       "  43.616579809538585,\n",
       "  70.11656146312963,\n",
       "  81.79875024469742,\n",
       "  66.5204674612108,\n",
       "  53.456756086932565,\n",
       "  81.64667017387374,\n",
       "  62.3835177278592,\n",
       "  53.38746885089609,\n",
       "  58.87793016064704,\n",
       "  90.33954870145185,\n",
       "  51.38123227555817,\n",
       "  80.89894417579,\n",
       "  44.772429833906074,\n",
       "  51.15243057346915,\n",
       "  39.05236931376261,\n",
       "  37.76062988427501],\n",
       " ((0.43615602120898206, 0.5584503323054474, 0.7056211104488621),\n",
       "  0.7202049410881086),\n",
       " {'F_LUpperArm': ['-0.127420514822',\n",
       "   '0.711297631264',\n",
       "   '0.244446054101',\n",
       "   '-0.0282963141799',\n",
       "   '-0.0228680893779',\n",
       "   '-0.0672974735498',\n",
       "   '0.99706941843'],\n",
       "  'Bedpan': ['2.01940226555',\n",
       "   '0.807986319065',\n",
       "   '0.023851942271',\n",
       "   '0.189490243793',\n",
       "   '0.551834046841',\n",
       "   '-0.0417181774974',\n",
       "   '0.811068534851'],\n",
       "  'BedHead': ['-0.826008796692',\n",
       "   '0.636754512787',\n",
       "   '-0.134028106928',\n",
       "   '-0.0810286030173',\n",
       "   '0.113587729633',\n",
       "   '0.113597333431',\n",
       "   '0.983680844307'],\n",
       "  'F_RThigh': ['-0.426488697529',\n",
       "   '0.715114057064',\n",
       "   '0.817434608936',\n",
       "   '0.0111533468589',\n",
       "   '-0.0837176963687',\n",
       "   '0.173890084028',\n",
       "   '0.981136739254'],\n",
       "  'BedFoot': ['-0.695240914822',\n",
       "   '0.620994329453',\n",
       "   '1.58748555183',\n",
       "   '0.00116079882719',\n",
       "   '0.0218012202531',\n",
       "   '-0.0157162640244',\n",
       "   '0.999638199806'],\n",
       "  'F_LThigh': ['-0.148632138968',\n",
       "   '0.705374956131',\n",
       "   '0.81747096777',\n",
       "   '-0.0202536676079',\n",
       "   '-0.0939685925841',\n",
       "   '-0.0576651915908',\n",
       "   '0.993697345257'],\n",
       "  'F_Hips': ['-0.298879504204',\n",
       "   '0.722189426422',\n",
       "   '0.539466977119',\n",
       "   '0.0251834262162',\n",
       "   '0.0228141117841',\n",
       "   '0.000559140520636',\n",
       "   '0.999422311783'],\n",
       "  'Hoyer_Top': ['0.783866524696',\n",
       "   '1.00536501408',\n",
       "   '0.938298344612',\n",
       "   '-0.112019918859',\n",
       "   '0.00871282443404',\n",
       "   '0.993401527405',\n",
       "   '-0.0230012629181'],\n",
       "  'F_RLowerArm': ['-0.55708527565',\n",
       "   '0.647277414799',\n",
       "   '0.597823321819',\n",
       "   '0.29603651166',\n",
       "   '0.0834952369332',\n",
       "   '0.172961801291',\n",
       "   '0.935668289661'],\n",
       "  'C_LeftHand': ['0.426946878433',\n",
       "   '1.29897725582',\n",
       "   '0.991337120533',\n",
       "   '0.49758297205',\n",
       "   '-0.860514223576',\n",
       "   '0.0698740184307',\n",
       "   '0.0839295685291'],\n",
       "  'C_RightHand': ['0.221607089043',\n",
       "   '0.672124862671',\n",
       "   '0.666551589966',\n",
       "   '-0.56429463625',\n",
       "   '0.0620392896235',\n",
       "   '-0.717933535576',\n",
       "   '-0.40285769105'],\n",
       "  'F_RUpperArm': ['-0.568866074085',\n",
       "   '0.705945551395',\n",
       "   '0.288642376661',\n",
       "   '-0.00860002916306',\n",
       "   '-0.0721534863114',\n",
       "   '-0.0277792196721',\n",
       "   '-0.996969521046'],\n",
       "  'C_Head': ['0.15996183455',\n",
       "   '1.45062184334',\n",
       "   '0.834740042686',\n",
       "   '-0.334504127502',\n",
       "   '0.66182744503',\n",
       "   '-0.0270289592445',\n",
       "   '-0.67034393549'],\n",
       "  'F_Torso': ['-0.33045014739',\n",
       "   '0.781032025814',\n",
       "   '0.244269564748',\n",
       "   '0.00828867033124',\n",
       "   '0.0288592968136',\n",
       "   '0.00563402660191',\n",
       "   '0.999533295631'],\n",
       "  'F_LCalf': ['-0.121192485094',\n",
       "   '0.653717517853',\n",
       "   '1.16793549061',\n",
       "   '0.00410929182544',\n",
       "   '-0.123251974583',\n",
       "   '-0.0558327920735',\n",
       "   '0.990795075893'],\n",
       "  'F_LLowerArm': ['-0.0796146318316',\n",
       "   '0.659309089184',\n",
       "   '0.517993330956',\n",
       "   '0.319955736399',\n",
       "   '0.00559254735708',\n",
       "   '0.0553634613752',\n",
       "   '0.945797085762'],\n",
       "  'F_RCalf': ['-0.445307165384',\n",
       "   '0.667503833771',\n",
       "   '1.19616675377',\n",
       "   '0.00645655207336',\n",
       "   '-0.100321464241',\n",
       "   '0.223739042878',\n",
       "   '0.969450771809'],\n",
       "  '': ['-0.382749319077',\n",
       "   '0.878066658974',\n",
       "   '0.0157650765032',\n",
       "   '-0.00178622605745',\n",
       "   '0.0546085983515',\n",
       "   '0.039763379842',\n",
       "   '0.997714161873'],\n",
       "  'Wheelchair': ['0.475571513176',\n",
       "   '1.03498899937',\n",
       "   '-0.879358649254',\n",
       "   '0.0481861829758',\n",
       "   '-0.00979604106396',\n",
       "   '-0.00414744718',\n",
       "   '0.998781740665']})"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = total_construct('18-0-7')\n",
    "data[69]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "971a9f6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2881"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1d5f809a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['F_RUpperArm', 'F_LUpperArm', 'F_LThigh', 'F_RThigh']\n",
      "Added shoulder-shoulder links\n",
      "Added torso-hip links\n",
      "Added hip-thigh links\n",
      "Adding link between F_RUpperArm and F_RUpperArm\n",
      "Adding link between F_LUpperArm and F_LUpperArm\n",
      "Adding link between F_LThigh and F_LThigh\n",
      "Adding link between F_RThigh and F_RThigh\n",
      "Adding link between F_LShoulder and F_RShoulder\n",
      "Adding link between F_LElbow and F_LWrist\n",
      "Adding link between F_RElbow and F_RWrist\n",
      "Adding link between F_Torso and F_Hips\n",
      "Adding link between F_LThigh and F_Hips\n",
      "Adding link between F_RThigh and F_Hips\n",
      "Adding link between F_LKnee and F_LAnkle\n",
      "Adding link between F_RKnee and F_RAnkle\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SceneViewer(width=1800, height=1350)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "def render_scene(data, index=None):\n",
    "    if index == None:\n",
    "        print(\"This is not done yet!\")\n",
    "        return False\n",
    "    \n",
    "    else:\n",
    "        skeleton_lines, centroids = skeleton_reconstruct(data[index][-1], 0)\n",
    "\n",
    "    scene = trimesh.Scene()\n",
    "    segments = []\n",
    "    for line in skeleton_lines:\n",
    "        points = []\n",
    "        texts = []\n",
    "        x, y, joint_1, joint_2 = line\n",
    "        segments.append(np.array([x, y]))\n",
    "        print(f\"Adding link between {joint_1} and {joint_2}\")\n",
    "\n",
    "    p = trimesh.load_path(segments)\n",
    "    scene = p.scene()\n",
    "    # for debugging purposes only\n",
    "    # pct = trimesh.PointCloud(np.array(centroids), colors=np.tile(np.array([255, 255, 255, 255]), (len(centroids), 1)))\n",
    "    # scene.add_geometry(pct)\n",
    "    \n",
    "    # add the caregiver's head\n",
    "    if \"C_Head\" in data[index][-1]:\n",
    "        head = trimesh.load_mesh('Head01.stl')\n",
    "        head.apply_transform(make_transformation_matrix(data[index][-1][\"C_Head\"]))\n",
    "        scene.add_geometry(head)\n",
    "        \n",
    "        # cast a cone in the direction of the gaze\n",
    "        \n",
    "        gaze_vector_norm, confidence = data[index][2]\n",
    "        gaze_vector_norm /= np.linalg.norm(gaze_vector_norm)\n",
    "        x_n, y_n, z_n = gaze_vector_norm\n",
    "        \n",
    "        static_transform = np.eye(4)\n",
    "        static_transform[1, 3] = -0.1\n",
    "        static_transform[2, 3] = -0.07\n",
    "        \n",
    "        import mathutils\n",
    "        quat1 = mathutils.Quaternion((x_n, y_n, z_n, 1))\n",
    "        quat1_norm = quat1.normalized()\n",
    "        \n",
    "        alpha = math.atan2(x_n, z_n) / 2\n",
    "        quat = [x_n * math.sin(alpha), y_n * math.sin(alpha), z_n * math.sin(alpha), math.cos(alpha)]\n",
    "        \n",
    "        gaze_rotation = np.eye(4)\n",
    "        gaze_rotation[:3, :3] = R.from_quat(quat).as_matrix()\n",
    "        \n",
    "        view_cone = trimesh.load_mesh('View.stl')\n",
    "        view_cone.apply_transform(gaze_rotation)\n",
    "        view_cone.apply_transform(make_transformation_matrix(data[index][-1][\"C_Head\"]))\n",
    "        view_cone.apply_transform(static_transform)\n",
    "        \n",
    "        \n",
    "        \n",
    "        scene.add_geometry(view_cone)\n",
    "    # add the caregiver's hands, represented as triangles\n",
    "    if \"C_LeftHand\" in data[index][-1]:\n",
    "        L_hand = trimesh.load_mesh('Hands.stl')\n",
    "        L_hand.apply_transform(make_transformation_matrix(data[index][-1][\"C_LeftHand\"]))\n",
    "        scene.add_geometry(L_hand)\n",
    "    \n",
    "    if \"C_RightHand\" in data[index][-1]:\n",
    "        R_hand = trimesh.load_mesh('Hands.stl')\n",
    "        R_hand.apply_transform(make_transformation_matrix(data[index][-1][\"C_RightHand\"]))\n",
    "        scene.add_geometry(R_hand)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return scene\n",
    "\n",
    "scene = render_scene(data, index=1000)\n",
    "scene.show(line_settings={'point_size':10}, viewer='gl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be66251d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1147b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pupil_data = load_pupil('11-1-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1694c6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pupil_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227536e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pupil_data[6533]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5c18fd9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<details>\n",
       "<summary>Click to view session information</summary>\n",
       "<pre>\n",
       "-----\n",
       "PIL                 10.0.0\n",
       "matplotlib          3.7.2\n",
       "mpl_toolkits        NA\n",
       "msgpack             1.0.3\n",
       "numpy               1.25.2\n",
       "rich                NA\n",
       "rosgraph            NA\n",
       "rospy               NA\n",
       "scipy               1.10.1\n",
       "session_info        1.0.0\n",
       "trimesh             3.23.1\n",
       "-----\n",
       "</pre>\n",
       "<details>\n",
       "<summary>Click to view modules imported as dependencies</summary>\n",
       "<pre>\n",
       "anyio                       NA\n",
       "asttokens                   NA\n",
       "attr                        22.1.0\n",
       "babel                       2.11.0\n",
       "backcall                    0.2.0\n",
       "brotli                      NA\n",
       "catkin                      NA\n",
       "catkin_pkg                  0.5.2\n",
       "certifi                     2023.05.07\n",
       "cffi                        1.15.1\n",
       "chardet                     4.0.0\n",
       "charset_normalizer          2.0.4\n",
       "colorama                    0.4.6\n",
       "comm                        0.1.2\n",
       "cycler                      0.10.0\n",
       "cython_runtime              NA\n",
       "dateutil                    2.8.2\n",
       "debugpy                     1.5.1\n",
       "decorator                   5.1.1\n",
       "defusedxml                  0.7.1\n",
       "executing                   1.2.0\n",
       "fastjsonschema              NA\n",
       "genmsg                      NA\n",
       "genpy                       NA\n",
       "idna                        3.4\n",
       "ipykernel                   6.19.2\n",
       "ipython_genutils            0.2.0\n",
       "ipywidgets                  8.0.4\n",
       "jedi                        0.19.0\n",
       "jinja2                      3.0.3\n",
       "json5                       NA\n",
       "jsonpointer                 2.1\n",
       "jsonschema                  4.17.3\n",
       "jupyter_events              0.6.3\n",
       "jupyter_server              2.5.0\n",
       "jupyterlab_server           2.22.0\n",
       "kiwisolver                  1.4.4\n",
       "lxml                        4.9.2\n",
       "markupsafe                  2.1.3\n",
       "mathutils                   NA\n",
       "nbformat                    5.7.0\n",
       "networkx                    2.8.4\n",
       "ntsecuritycon               NA\n",
       "packaging                   21.3\n",
       "parso                       0.8.3\n",
       "pickleshare                 0.7.5\n",
       "pkg_resources               NA\n",
       "platformdirs                2.5.2\n",
       "prometheus_client           NA\n",
       "prompt_toolkit              3.0.39\n",
       "psutil                      5.9.5\n",
       "pure_eval                   0.2.2\n",
       "pvectorc                    NA\n",
       "pydev_ipython               NA\n",
       "pydevconsole                NA\n",
       "pydevd                      2.6.0\n",
       "pydevd_concurrency_analyser NA\n",
       "pydevd_file_utils           NA\n",
       "pydevd_plugins              NA\n",
       "pydevd_tracing              NA\n",
       "pyglet                      1.5.27\n",
       "pygments                    2.16.1\n",
       "pyparsing                   3.0.9\n",
       "pyrsistent                  NA\n",
       "pythoncom                   NA\n",
       "pythonjsonlogger            NA\n",
       "pywintypes                  NA\n",
       "requests                    2.29.0\n",
       "rfc3339_validator           0.1.4\n",
       "rfc3986_validator           0.1.1\n",
       "roscpp                      NA\n",
       "rosgraph_msgs               NA\n",
       "roslib                      1.7.0\n",
       "rospkg                      1.5.0\n",
       "ruamel                      NA\n",
       "send2trash                  NA\n",
       "six                         1.16.0\n",
       "sniffio                     1.2.0\n",
       "socks                       1.7.1\n",
       "sphinxcontrib               NA\n",
       "stack_data                  0.6.2\n",
       "std_msgs                    NA\n",
       "tornado                     6.2\n",
       "traitlets                   5.9.0\n",
       "urllib3                     1.26.16\n",
       "wcwidth                     0.2.6\n",
       "websocket                   0.58.0\n",
       "win32api                    NA\n",
       "win32com                    NA\n",
       "win32con                    NA\n",
       "win32security               NA\n",
       "win32trace                  NA\n",
       "winerror                    NA\n",
       "yaml                        6.0.1\n",
       "zmq                         25.1.0\n",
       "zope                        NA\n",
       "</pre>\n",
       "</details> <!-- seems like this ends pre, so might as well be explicit -->\n",
       "<pre>\n",
       "-----\n",
       "IPython             8.14.0\n",
       "jupyter_client      8.1.0\n",
       "jupyter_core        5.3.0\n",
       "jupyterlab          3.6.3\n",
       "notebook            6.5.4\n",
       "-----\n",
       "Python 3.11.3 | packaged by Anaconda, Inc. | (main, Apr 19 2023, 23:46:34) [MSC v.1916 64 bit (AMD64)]\n",
       "Windows-10-10.0.19045-SP0\n",
       "-----\n",
       "Session information updated at 2023-10-09 18:47\n",
       "</pre>\n",
       "</details>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session_info.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a5765b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
